//! Auto-edit from text prompt — AI assembles a rough cut from media pool.
//!
//! A cloud-based "Director Agent" (Claude) plans the edit based on
//! media pool metadata and transcripts. All execution is local and
//! deterministic. No raw footage is sent to the cloud.
//!
//! This feature is opt-in and requires an internet connection + API key.

use crate::error::{AiError, AiResult};
use serde::{Deserialize, Serialize};

/// An edit plan generated by the Director Agent.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EditPlan {
    /// Ordered list of clip placements.
    pub clips: Vec<ClipInstruction>,
    /// Transitions between clips.
    pub transitions: Vec<TransitionInstruction>,
    /// Text overlay instructions.
    pub text_overlays: Vec<TextOverlayInstruction>,
    /// Suggested background music track (from media pool).
    pub music_track: Option<String>,
    /// Overall pacing notes from the AI.
    pub notes: String,
}

/// Instruction to place a specific clip on the timeline.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ClipInstruction {
    /// Asset ID in the media pool.
    pub asset_id: String,
    /// In-point within the source clip (seconds).
    pub in_point: f64,
    /// Out-point within the source clip (seconds).
    pub out_point: f64,
    /// Position on the output timeline (seconds).
    pub timeline_position: f64,
    /// Track index (0 = primary video, 1+ = overlay).
    pub track: u32,
}

/// Instruction to add a transition between clips.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TransitionInstruction {
    /// Time on the timeline (seconds).
    pub time: f64,
    /// Type of transition.
    pub transition_type: String,
    /// Duration of the transition (seconds).
    pub duration: f64,
}

/// Instruction to add a text overlay.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TextOverlayInstruction {
    /// Text content.
    pub text: String,
    /// Start time (seconds).
    pub start: f64,
    /// End time (seconds).
    pub end: f64,
    /// Position on screen (normalized 0.0 to 1.0).
    pub position_x: f32,
    /// Position on screen (normalized 0.0 to 1.0).
    pub position_y: f32,
    /// Font size (points).
    pub font_size: f32,
}

/// Summary of a media asset for the Director Agent.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MediaAssetSummary {
    /// Unique asset identifier.
    pub asset_id: String,
    /// Filename.
    pub filename: String,
    /// Duration in seconds.
    pub duration: f64,
    /// Transcript text (if available).
    pub transcript: Option<String>,
    /// Scene descriptions.
    pub scene_descriptions: Vec<String>,
    /// Shot types detected.
    pub shot_types: Vec<String>,
    /// Speakers detected.
    pub speakers: Vec<String>,
    /// Audio type (dialogue, music, ambient).
    pub audio_type: String,
}

/// Configuration for the auto-editor.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AutoEditConfig {
    /// API endpoint URL.
    pub api_url: String,
    /// API key.
    pub api_key: String,
    /// Model to use.
    pub model: String,
    /// Maximum output tokens.
    pub max_tokens: u32,
}

impl Default for AutoEditConfig {
    fn default() -> Self {
        Self {
            api_url: "https://api.anthropic.com/v1/messages".into(),
            api_key: String::new(),
            model: "claude-sonnet-4-5-20250929".into(),
            max_tokens: 8192,
        }
    }
}

/// The AI auto-editor: generates edit plans from text prompts.
pub struct AutoEditor {
    config: AutoEditConfig,
}

impl AutoEditor {
    /// Create a new auto-editor.
    pub fn new(config: AutoEditConfig) -> AiResult<Self> {
        if config.api_key.is_empty() {
            return Err(AiError::CloudApiError(
                "API key is required for auto-edit".into(),
            ));
        }
        Ok(Self { config })
    }

    /// Check if the editor is configured.
    pub fn is_configured(&self) -> bool {
        !self.config.api_key.is_empty()
    }

    /// Generate an edit plan from a text prompt and media pool.
    ///
    /// Sends media summaries (NOT raw footage) to the cloud Director Agent,
    /// which returns a structured edit plan that can be executed locally.
    pub async fn generate_edit(
        &self,
        _prompt: &str,
        media_pool: &[MediaAssetSummary],
        target_duration: Option<f64>,
    ) -> AiResult<EditPlan> {
        if !self.is_configured() {
            return Err(AiError::CloudApiError("API key not configured".into()));
        }
        if media_pool.is_empty() {
            return Err(AiError::PreprocessError(
                "Media pool is empty — import footage first".into(),
            ));
        }

        // Build the media pool summary for the prompt
        let _pool_summary = build_media_summary(media_pool);

        // In production, this would call the Claude API with:
        // - System prompt: DIRECTOR_SYSTEM_PROMPT
        // - User prompt: the user's request + media pool summary
        // - Expected response: JSON EditPlan
        //
        // For now, generate a simple sequential edit as fallback.
        Ok(generate_simple_edit(media_pool, target_duration))
    }
}

/// Build a text summary of the media pool for the Director Agent prompt.
fn build_media_summary(pool: &[MediaAssetSummary]) -> String {
    let mut summary = String::new();
    for (i, asset) in pool.iter().enumerate() {
        summary.push_str(&format!(
            "{}. [{}] \"{}\" ({:.1}s) — ",
            i + 1,
            asset.asset_id,
            asset.filename,
            asset.duration,
        ));
        if let Some(ref transcript) = asset.transcript {
            let preview: String = transcript.chars().take(100).collect();
            summary.push_str(&format!("transcript: \"{preview}...\" "));
        }
        if !asset.scene_descriptions.is_empty() {
            summary.push_str(&format!("scenes: [{}] ", asset.scene_descriptions.join(", ")));
        }
        summary.push_str(&format!("audio: {}", asset.audio_type));
        summary.push('\n');
    }
    summary
}

/// Generate a simple sequential edit as a fallback when cloud is unavailable.
fn generate_simple_edit(
    pool: &[MediaAssetSummary],
    target_duration: Option<f64>,
) -> EditPlan {
    let target = target_duration.unwrap_or(60.0);
    let mut clips = Vec::new();
    let mut timeline_pos = 0.0;

    for asset in pool {
        if timeline_pos >= target {
            break;
        }

        let remaining = target - timeline_pos;
        let clip_duration = asset.duration.min(remaining).min(10.0); // max 10s per clip

        clips.push(ClipInstruction {
            asset_id: asset.asset_id.clone(),
            in_point: 0.0,
            out_point: clip_duration,
            timeline_position: timeline_pos,
            track: 0,
        });

        timeline_pos += clip_duration;
    }

    // Add simple cut transitions between clips
    let transitions: Vec<TransitionInstruction> = clips
        .windows(2)
        .map(|pair| TransitionInstruction {
            time: pair[0].timeline_position + (pair[0].out_point - pair[0].in_point),
            transition_type: "cut".into(),
            duration: 0.0,
        })
        .collect();

    EditPlan {
        clips,
        transitions,
        text_overlays: Vec::new(),
        music_track: None,
        notes: "Simple sequential edit (offline fallback)".into(),
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    fn make_test_pool() -> Vec<MediaAssetSummary> {
        vec![
            MediaAssetSummary {
                asset_id: "clip_001".into(),
                filename: "interview_part1.mp4".into(),
                duration: 30.0,
                transcript: Some("Hello and welcome to the show".into()),
                scene_descriptions: vec!["close-up of speaker".into()],
                shot_types: vec!["close-up".into()],
                speakers: vec!["Speaker A".into()],
                audio_type: "dialogue".into(),
            },
            MediaAssetSummary {
                asset_id: "clip_002".into(),
                filename: "broll_city.mp4".into(),
                duration: 15.0,
                transcript: None,
                scene_descriptions: vec!["aerial city shot".into()],
                shot_types: vec!["wide".into()],
                speakers: vec![],
                audio_type: "ambient".into(),
            },
            MediaAssetSummary {
                asset_id: "clip_003".into(),
                filename: "interview_part2.mp4".into(),
                duration: 45.0,
                transcript: Some("That's a great question, let me explain".into()),
                scene_descriptions: vec!["medium shot of speaker".into()],
                shot_types: vec!["medium".into()],
                speakers: vec!["Speaker A".into()],
                audio_type: "dialogue".into(),
            },
        ]
    }

    #[test]
    fn test_auto_editor_requires_api_key() {
        let config = AutoEditConfig::default();
        assert!(AutoEditor::new(config).is_err());
    }

    #[test]
    fn test_auto_editor_creation() {
        let config = AutoEditConfig {
            api_key: "test-key".into(),
            ..Default::default()
        };
        let editor = AutoEditor::new(config).unwrap();
        assert!(editor.is_configured());
    }

    #[test]
    fn test_generate_simple_edit() {
        let pool = make_test_pool();
        let plan = generate_simple_edit(&pool, Some(20.0));

        assert!(!plan.clips.is_empty());
        // Total planned duration should not exceed target
        let total: f64 = plan
            .clips
            .iter()
            .map(|c| c.out_point - c.in_point)
            .sum();
        assert!(total <= 20.5, "Total duration {total} should be <= ~20s");
    }

    #[test]
    fn test_simple_edit_respects_target_duration() {
        let pool = make_test_pool();
        let plan = generate_simple_edit(&pool, Some(5.0));

        let total: f64 = plan.clips.iter().map(|c| c.out_point - c.in_point).sum();
        assert!(total <= 5.5, "Should respect 5s target, got {total}");
    }

    #[test]
    fn test_edit_plan_serialization() {
        let plan = EditPlan {
            clips: vec![ClipInstruction {
                asset_id: "test".into(),
                in_point: 0.0,
                out_point: 5.0,
                timeline_position: 0.0,
                track: 0,
            }],
            transitions: vec![],
            text_overlays: vec![],
            music_track: None,
            notes: "test plan".into(),
        };

        let json = serde_json::to_string(&plan).unwrap();
        let decoded: EditPlan = serde_json::from_str(&json).unwrap();
        assert_eq!(decoded.clips.len(), 1);
        assert_eq!(decoded.clips[0].asset_id, "test");
    }

    #[test]
    fn test_build_media_summary() {
        let pool = make_test_pool();
        let summary = build_media_summary(&pool);
        assert!(summary.contains("interview_part1.mp4"));
        assert!(summary.contains("clip_001"));
        assert!(summary.contains("dialogue"));
    }

    #[test]
    fn test_transitions_between_clips() {
        let pool = make_test_pool();
        let plan = generate_simple_edit(&pool, Some(30.0));
        if plan.clips.len() > 1 {
            assert_eq!(
                plan.transitions.len(),
                plan.clips.len() - 1,
                "Should have one transition between each pair of clips"
            );
        }
    }
}
